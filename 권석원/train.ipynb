{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP+h/9/vajltJeMo3AflFID"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYDavqHdcPnQ","executionInfo":{"status":"ok","timestamp":1680881277645,"user_tz":-540,"elapsed":22245,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"4c216058-f68c-4874-c88c-d81dfc0f360b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["https://aifactory.space/competition/detail/2226"],"metadata":{"id":"hmSAwiBtH_WX"}},{"cell_type":"markdown","source":["# Git"],"metadata":{"id":"HSRwtA2yc7Dd"}},{"cell_type":"code","source":["cd /content/drive/MyDrive/Colab Notebooks/AI_SPARK/AI_SPARK_Challenge_2023"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XxDFG79pdzNB","executionInfo":{"status":"ok","timestamp":1680881285443,"user_tz":-540,"elapsed":868,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"7e8df3fa-c4ae-46f8-eecc-f1cf2000b398"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/AI_SPARK/AI_SPARK_Challenge_2023\n"]}]},{"cell_type":"markdown","source":["브랜치\n","- master\n","- ksw_main"],"metadata":{"id":"7FXUes01ehtr"}},{"cell_type":"code","source":["!git branch ksw_main"],"metadata":{"id":"RWcvffnyc-BO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git checkout master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7jmI9f5duW6","executionInfo":{"status":"ok","timestamp":1680615685152,"user_tz":-540,"elapsed":313,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"546bc1e3-0396-4145-86ac-1c38c0dd4caa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Switched to branch 'master'\n","Your branch is up to date with 'origin/master'.\n"]}]},{"cell_type":"code","source":["!git remote update\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Cv1zo8gfl6-","executionInfo":{"status":"ok","timestamp":1680615637948,"user_tz":-540,"elapsed":1744,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"37c07313-cf27-4f9d-ef30-1f7a3d0409ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fetching origin\n","Already on 'ksw_main'\n"]}]},{"cell_type":"code","source":["!git checkout ksw_main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"coHq-2JSHnAy","executionInfo":{"status":"ok","timestamp":1680626056248,"user_tz":-540,"elapsed":1405,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"8555adfb-602b-4377-85d7-14e244a97b0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Switched to branch 'ksw_main'\n"]}]},{"cell_type":"code","source":["!git add --all"],"metadata":{"id":"Zo_ivPtuHzm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git branch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLznqdmGf_ZN","executionInfo":{"status":"ok","timestamp":1680708851434,"user_tz":-540,"elapsed":1611,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"5d16d382-ae73-4720-f7f1-11dab9917e87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  ksw_main\u001b[m\n","* \u001b[32mmaster\u001b[m\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"dhjkl123@naver.com\"\n","!git config --global user.name \"dhjkl123\"\n","!git commit -m '20230408 ksw 20시 제출'"],"metadata":{"id":"E86_WKt5DhJM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680879380712,"user_tz":-540,"elapsed":5273,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"07367e5c-675a-4e98-fcee-367e59fe20e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[master 92e3ce8] 20230407 ksw 20시 제출\n"," 11 files changed, 2 insertions(+), 2 deletions(-)\n"," create mode 100644 \"\\341\\204\\200\\341\\205\\257\\341\\206\\253\\341\\204\\211\\341\\205\\245\\341\\206\\250\\341\\204\\213\\341\\205\\257\\341\\206\\253/m_1.h5\"\n"," create mode 100644 \"\\341\\204\\200\\341\\205\\257\\341\\206\\253\\341\\204\\211\\341\\205\\245\\341\\206\\250\\341\\204\\213\\341\\205\\257\\341\\206\\253/m_2.h5\"\n"," create mode 100644 \"\\341\\204\\200\\341\\205\\257\\341\\206\\253\\341\\204\\211\\341\\205\\245\\341\\206\\250\\341\\204\\213\\341\\205\\257\\341\\206\\253/m_5.h5\"\n"," create mode 100644 \"\\341\\204\\200\\341\\205\\257\\341\\206\\253\\341\\204\\211\\341\\205\\245\\341\\206\\250\\341\\204\\213\\341\\205\\257\\341\\206\\253/m_e.h5\"\n"," create mode 100644 \"\\341\\204\\200\\341\\205\\257\\341\\206\\253\\341\\204\\211\\341\\205\\245\\341\\206\\250\\341\\204\\213\\341\\205\\257\\341\\206\\253/s_1.pickle\"\n"," create mode 100644 \"\\341\\204\\200\\341\\205\\257\\341\\206\\253\\341\\204\\211\\341\\205\\245\\341\\206\\250\\341\\204\\213\\341\\205\\257\\341\\206\\253/s_2.pickle\"\n"," create mode 100644 \"\\341\\204\\200\\341\\205\\257\\341\\206\\253\\341\\204\\211\\341\\205\\245\\341\\206\\250\\341\\204\\213\\341\\205\\257\\341\\206\\253/s_5.pickle\"\n"," create mode 100644 \"\\341\\204\\200\\341\\205\\257\\341\\206\\253\\341\\204\\211\\341\\205\\245\\341\\206\\250\\341\\204\\213\\341\\205\\257\\341\\206\\253/s_e.pickle\"\n"," rewrite \"\\341\\204\\200\\341\\205\\257\\341\\206\\253\\341\\204\\211\\341\\205\\245\\341\\206\\250\\341\\204\\213\\341\\205\\257\\341\\206\\253/test.ipynb\" (97%)\n"," rewrite \"\\341\\204\\200\\341\\205\\257\\341\\206\\253\\341\\204\\211\\341\\205\\245\\341\\206\\250\\341\\204\\213\\341\\205\\257\\341\\206\\253/train.ipynb\" (94%)\n"]}]},{"cell_type":"code","source":["!git push"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZOAxrHXlalZ-","executionInfo":{"status":"ok","timestamp":1680879514920,"user_tz":-540,"elapsed":1531,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"2c14e60f-b862-44ae-975f-a86039f3be20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["To https://github.com/dhjkl123/AI_SPARK_Challenge_2023.git\n"," \u001b[31m! [rejected]       \u001b[m master -> master (non-fast-forward)\n","\u001b[31merror: failed to push some refs to 'https://dhjkl123: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@github.com/dhjkl123/AI_SPARK_Challenge_2023.git'\n","\u001b[m\u001b[33mhint: Updates were rejected because the tip of your current branch is behind\u001b[m\n","\u001b[33mhint: its remote counterpart. Integrate the remote changes (e.g.\u001b[m\n","\u001b[33mhint: 'git pull ...') before pushing again.\u001b[m\n","\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n"]}]},{"cell_type":"code","source":["!git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59jvLcryODNQ","executionInfo":{"status":"ok","timestamp":1680881302042,"user_tz":-540,"elapsed":9058,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"228334a2-865b-4b7e-8cde-1c59c48f3759"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Already up to date.\n"]}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"6WnS_WVTen-0"}},{"cell_type":"markdown","source":["## Import"],"metadata":{"id":"RxCkpD2LfF9n"}},{"cell_type":"code","source":["!pip install pyod"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVufNwoQDD4W","executionInfo":{"status":"ok","timestamp":1680881327437,"user_tz":-540,"elapsed":4983,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"26ace67c-f4bc-496f-c740-a0870b55bb1a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyod\n","  Downloading pyod-1.0.9.tar.gz (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.0/150.0 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from pyod) (1.1.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from pyod) (3.7.1)\n","Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.9/dist-packages (from pyod) (1.22.4)\n","Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.9/dist-packages (from pyod) (0.56.4)\n","Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from pyod) (1.10.1)\n","Requirement already satisfied: scikit_learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from pyod) (1.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from pyod) (1.16.0)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.51->pyod) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.51->pyod) (67.6.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit_learn>=0.20.0->pyod) (3.1.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pyod) (1.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pyod) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pyod) (4.39.3)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pyod) (5.12.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pyod) (2.8.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pyod) (8.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pyod) (23.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pyod) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->pyod) (3.0.9)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->pyod) (3.15.0)\n","Building wheels for collected packages: pyod\n","  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyod: filename=pyod-1.0.9-py3-none-any.whl size=184112 sha256=c4b093d60608a6b6dd0918583646da0c7c25659d96b9685f0de83a7cb5690105\n","  Stored in directory: /root/.cache/pip/wheels/1b/9c/b8/9759d7cc64a1e01bb9872ade80cb7db445ccf506e083325106\n","Successfully built pyod\n","Installing collected packages: pyod\n","Successfully installed pyod-1.0.9\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.metrics import *\n","\n","from pyod.models.abod import ABOD\n","from pyod.models.deep_svdd import DeepSVDD\n","from sklearn.ensemble import IsolationForest\n","\n","import tensorflow as tf\n","from keras.layers import Input, Dense, BatchNormalization, Dropout\n","from keras.models import Model\n","from keras.callbacks import EarlyStopping\n","from keras.backend import clear_session\n","\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"KkQWUsYufHvD","executionInfo":{"status":"ok","timestamp":1680881433322,"user_tz":-540,"elapsed":302,"user":{"displayName":"권석원","userId":"05764927584241177010"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Data Load"],"metadata":{"id":"CfhBGFmBeqfk"}},{"cell_type":"code","source":["df_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AI_SPARK/Data/train_data.csv')"],"metadata":{"id":"pdXRJkKeeeSX","executionInfo":{"status":"ok","timestamp":1680882437467,"user_tz":-540,"elapsed":360,"user":{"displayName":"권석원","userId":"05764927584241177010"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def tyep_to_hp(type_no):\n","  if type_no == 1:\n","    return 20\n","  elif type_no == 2:\n","    return 10\n","  elif type_no == 3:\n","    return 50\n","  else:\n","    return 30\n","\n","\n","df_data = df_data.drop(axis=1, columns=['out_pressure'])\n","df_data['type'] = df_data['type'].apply(tyep_to_hp)\n"],"metadata":{"id":"Wytg6Kzug16F","executionInfo":{"status":"ok","timestamp":1680882439621,"user_tz":-540,"elapsed":1,"user":{"displayName":"권석원","userId":"05764927584241177010"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["df_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"u5IE-Nal0s1-","executionInfo":{"status":"ok","timestamp":1680882442224,"user_tz":-540,"elapsed":270,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"f7a32144-3f3d-4424-d9f7-f288c5b74037"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      air_inflow  air_end_temp  motor_current  motor_rpm  motor_temp  \\\n","0           1.59         41.00          20.53     1680.0       58.67   \n","1           2.97         59.28          38.40     3142.0       74.91   \n","2           1.91         45.29          24.73     2023.0       62.48   \n","3           2.37         51.33          30.63     2506.0       67.84   \n","4           1.90         45.21          24.65     2017.0       62.41   \n","...          ...           ...            ...        ...         ...   \n","2458        2.28         50.20          29.53     2416.0       66.84   \n","2459        2.04         46.94          26.34     2155.0       63.94   \n","2460        1.19         35.74          15.39     1259.0       53.99   \n","2461        1.21         36.00          15.64     1280.0       54.22   \n","2462        2.72         55.99          35.19     2879.0       71.99   \n","\n","      motor_vibe  type  \n","0           2.93    30  \n","1           3.75    30  \n","2           3.12    30  \n","3           3.39    30  \n","4           3.12    30  \n","...          ...   ...  \n","2458        3.34    30  \n","2459        3.20    30  \n","2460        2.70    30  \n","2461        2.71    30  \n","2462        3.60    30  \n","\n","[2463 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-93faa097-a0f2-465a-9a6d-6fb9db40c040\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>air_inflow</th>\n","      <th>air_end_temp</th>\n","      <th>motor_current</th>\n","      <th>motor_rpm</th>\n","      <th>motor_temp</th>\n","      <th>motor_vibe</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.59</td>\n","      <td>41.00</td>\n","      <td>20.53</td>\n","      <td>1680.0</td>\n","      <td>58.67</td>\n","      <td>2.93</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.97</td>\n","      <td>59.28</td>\n","      <td>38.40</td>\n","      <td>3142.0</td>\n","      <td>74.91</td>\n","      <td>3.75</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.91</td>\n","      <td>45.29</td>\n","      <td>24.73</td>\n","      <td>2023.0</td>\n","      <td>62.48</td>\n","      <td>3.12</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.37</td>\n","      <td>51.33</td>\n","      <td>30.63</td>\n","      <td>2506.0</td>\n","      <td>67.84</td>\n","      <td>3.39</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.90</td>\n","      <td>45.21</td>\n","      <td>24.65</td>\n","      <td>2017.0</td>\n","      <td>62.41</td>\n","      <td>3.12</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2458</th>\n","      <td>2.28</td>\n","      <td>50.20</td>\n","      <td>29.53</td>\n","      <td>2416.0</td>\n","      <td>66.84</td>\n","      <td>3.34</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2459</th>\n","      <td>2.04</td>\n","      <td>46.94</td>\n","      <td>26.34</td>\n","      <td>2155.0</td>\n","      <td>63.94</td>\n","      <td>3.20</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2460</th>\n","      <td>1.19</td>\n","      <td>35.74</td>\n","      <td>15.39</td>\n","      <td>1259.0</td>\n","      <td>53.99</td>\n","      <td>2.70</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2461</th>\n","      <td>1.21</td>\n","      <td>36.00</td>\n","      <td>15.64</td>\n","      <td>1280.0</td>\n","      <td>54.22</td>\n","      <td>2.71</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2462</th>\n","      <td>2.72</td>\n","      <td>55.99</td>\n","      <td>35.19</td>\n","      <td>2879.0</td>\n","      <td>71.99</td>\n","      <td>3.60</td>\n","      <td>30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2463 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93faa097-a0f2-465a-9a6d-6fb9db40c040')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-93faa097-a0f2-465a-9a6d-6fb9db40c040 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-93faa097-a0f2-465a-9a6d-6fb9db40c040');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["df_data = df_data[(df_data['motor_vibe'] < 5) & (df_data['air_inflow'] < 3.5) & (df_data['motor_current'] < 45) & (df_data['air_end_temp'] > 35) & (df_data['motor_temp'] > 53) ]"],"metadata":{"id":"kwQ3FVBvBdu2","executionInfo":{"status":"ok","timestamp":1680882442499,"user_tz":-540,"elapsed":1,"user":{"displayName":"권석원","userId":"05764927584241177010"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["df_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"o7e3eNE_FCKI","executionInfo":{"status":"ok","timestamp":1680882444524,"user_tz":-540,"elapsed":328,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"21c1ec94-ab47-42d9-cb6e-e1ceb359c726"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      air_inflow  air_end_temp  motor_current  motor_rpm  motor_temp  \\\n","0           1.59         41.00          20.53     1680.0       58.67   \n","1           2.97         59.28          38.40     3142.0       74.91   \n","2           1.91         45.29          24.73     2023.0       62.48   \n","3           2.37         51.33          30.63     2506.0       67.84   \n","4           1.90         45.21          24.65     2017.0       62.41   \n","...          ...           ...            ...        ...         ...   \n","2458        2.28         50.20          29.53     2416.0       66.84   \n","2459        2.04         46.94          26.34     2155.0       63.94   \n","2460        1.19         35.74          15.39     1259.0       53.99   \n","2461        1.21         36.00          15.64     1280.0       54.22   \n","2462        2.72         55.99          35.19     2879.0       71.99   \n","\n","      motor_vibe  type  \n","0           2.93    30  \n","1           3.75    30  \n","2           3.12    30  \n","3           3.39    30  \n","4           3.12    30  \n","...          ...   ...  \n","2458        3.34    30  \n","2459        3.20    30  \n","2460        2.70    30  \n","2461        2.71    30  \n","2462        3.60    30  \n","\n","[2161 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-0431ea6b-aa97-418c-b302-0013880e3781\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>air_inflow</th>\n","      <th>air_end_temp</th>\n","      <th>motor_current</th>\n","      <th>motor_rpm</th>\n","      <th>motor_temp</th>\n","      <th>motor_vibe</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.59</td>\n","      <td>41.00</td>\n","      <td>20.53</td>\n","      <td>1680.0</td>\n","      <td>58.67</td>\n","      <td>2.93</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.97</td>\n","      <td>59.28</td>\n","      <td>38.40</td>\n","      <td>3142.0</td>\n","      <td>74.91</td>\n","      <td>3.75</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.91</td>\n","      <td>45.29</td>\n","      <td>24.73</td>\n","      <td>2023.0</td>\n","      <td>62.48</td>\n","      <td>3.12</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.37</td>\n","      <td>51.33</td>\n","      <td>30.63</td>\n","      <td>2506.0</td>\n","      <td>67.84</td>\n","      <td>3.39</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.90</td>\n","      <td>45.21</td>\n","      <td>24.65</td>\n","      <td>2017.0</td>\n","      <td>62.41</td>\n","      <td>3.12</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2458</th>\n","      <td>2.28</td>\n","      <td>50.20</td>\n","      <td>29.53</td>\n","      <td>2416.0</td>\n","      <td>66.84</td>\n","      <td>3.34</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2459</th>\n","      <td>2.04</td>\n","      <td>46.94</td>\n","      <td>26.34</td>\n","      <td>2155.0</td>\n","      <td>63.94</td>\n","      <td>3.20</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2460</th>\n","      <td>1.19</td>\n","      <td>35.74</td>\n","      <td>15.39</td>\n","      <td>1259.0</td>\n","      <td>53.99</td>\n","      <td>2.70</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2461</th>\n","      <td>1.21</td>\n","      <td>36.00</td>\n","      <td>15.64</td>\n","      <td>1280.0</td>\n","      <td>54.22</td>\n","      <td>2.71</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>2462</th>\n","      <td>2.72</td>\n","      <td>55.99</td>\n","      <td>35.19</td>\n","      <td>2879.0</td>\n","      <td>71.99</td>\n","      <td>3.60</td>\n","      <td>30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2161 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0431ea6b-aa97-418c-b302-0013880e3781')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0431ea6b-aa97-418c-b302-0013880e3781 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0431ea6b-aa97-418c-b302-0013880e3781');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## AutoEncoder"],"metadata":{"id":"HUeE_tNJlnyx"}},{"cell_type":"code","source":["clear_session()\n","\n","def model(n_inputs):\n","  #n_inputs = df_data.shape[1]\n","\n","  # configure\n","  input_data = Input(shape=(n_inputs,))\n","\n","  # layers\n","  encoded = Dense(n_inputs//2, activation='relu')(input_data)\n","  batnorm = BatchNormalization()(encoded)\n","  dropout = Dropout(0.2)(batnorm)\n","  encoded = Dense(n_inputs//4, activation='relu')(dropout)\n","  batnorm = BatchNormalization()(encoded)\n","  dropout = Dropout(0.2)(batnorm)\n","\n","  n_bottneck = 200\n","  bottneck = Dense(n_bottneck, activation='relu')(dropout)\n","\n","  decoded = Dense(n_inputs//4, activation='relu')(bottneck)\n","  batnorm = BatchNormalization()(decoded)\n","  dropout = Dropout(0.2)(batnorm)\n","  decoded = Dense(n_inputs//2, activation='relu')(dropout)\n","  batnorm = BatchNormalization()(decoded)\n","  dropout = Dropout(0.2)(batnorm)\n","  decoded = Dense(n_inputs, activation='relu')(dropout)\n","\n","  # Models\n","  autoencoder = Model(input_data, decoded) # autoencoder\n","\n","  encoder = Model(input_data, encoded) # encoder\n","  return autoencoder"],"metadata":{"id":"VI2f9BmMBWko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clear_session()\n","\n","n_inputs = df_data.shape[1]\n","\n","# configure\n","input_data = Input(shape=(n_inputs,))\n","\n","# layers\n","encoded = Dense(n_inputs//2, activation='relu')(input_data)\n","batnorm = BatchNormalization()(encoded)\n","dropout = Dropout(0.2)(batnorm)\n","encoded = Dense(n_inputs//4, activation='relu')(dropout)\n","batnorm = BatchNormalization()(encoded)\n","dropout = Dropout(0.2)(batnorm)\n","\n","n_bottneck = 200\n","bottneck = Dense(n_bottneck, activation='relu')(dropout)\n","\n","decoded = Dense(n_inputs//4, activation='relu')(bottneck)\n","batnorm = BatchNormalization()(decoded)\n","dropout = Dropout(0.2)(batnorm)\n","decoded = Dense(n_inputs//2, activation='relu')(dropout)\n","batnorm = BatchNormalization()(decoded)\n","dropout = Dropout(0.2)(batnorm)\n","decoded = Dense(n_inputs, activation='relu')(dropout)\n","\n","# Models\n","autoencoder = Model(input_data, decoded) # autoencoder\n","\n","encoder = Model(input_data, encoded) # encoder"],"metadata":{"id":"LVRgOwxclqAS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["autoencoder.compile(optimizer='adam', loss='mse')"],"metadata":{"id":"zUgzp4fJovFo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["es = EarlyStopping(monitor = 'val_loss',patience=5,restore_best_weights=True, verbose=1)"],"metadata":{"id":"hEUV4gzGpnnz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = MinMaxScaler()\n","train_df = scaler.fit_transform(df_data)"],"metadata":{"id":"jyc4pxkozGph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train, x_val, _, _ = train_test_split(train_df,train_df,random_state=2023,test_size=0.3)\n","\n","autoencoder.fit(x_train, x_train, epochs = 100, callbacks = [es], validation_split = 0.3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qIueqt9rtTG","executionInfo":{"status":"ok","timestamp":1680855846739,"user_tz":-540,"elapsed":10289,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"ceffafb3-2f18-49e7-a2d8-b9c54c563725"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","34/34 [==============================] - 3s 13ms/step - loss: 0.3144 - val_loss: 0.3070\n","Epoch 2/100\n","34/34 [==============================] - 0s 7ms/step - loss: 0.2584 - val_loss: 0.2951\n","Epoch 3/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.2476 - val_loss: 0.2762\n","Epoch 4/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.2251 - val_loss: 0.2506\n","Epoch 5/100\n","34/34 [==============================] - 0s 7ms/step - loss: 0.2047 - val_loss: 0.2253\n","Epoch 6/100\n","34/34 [==============================] - 0s 6ms/step - loss: 0.1836 - val_loss: 0.2060\n","Epoch 7/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.1695 - val_loss: 0.1908\n","Epoch 8/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.1583 - val_loss: 0.1789\n","Epoch 9/100\n","34/34 [==============================] - 0s 6ms/step - loss: 0.1487 - val_loss: 0.1703\n","Epoch 10/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.1445 - val_loss: 0.1635\n","Epoch 11/100\n","34/34 [==============================] - 0s 6ms/step - loss: 0.1398 - val_loss: 0.1589\n","Epoch 12/100\n","34/34 [==============================] - 0s 7ms/step - loss: 0.1375 - val_loss: 0.1558\n","Epoch 13/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.1333 - val_loss: 0.1531\n","Epoch 14/100\n","34/34 [==============================] - 0s 6ms/step - loss: 0.1324 - val_loss: 0.1467\n","Epoch 15/100\n","34/34 [==============================] - 0s 7ms/step - loss: 0.1275 - val_loss: 0.1329\n","Epoch 16/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.1202 - val_loss: 0.0917\n","Epoch 17/100\n","34/34 [==============================] - 0s 6ms/step - loss: 0.0907 - val_loss: 0.0805\n","Epoch 18/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.0773 - val_loss: 0.0782\n","Epoch 19/100\n","34/34 [==============================] - 0s 7ms/step - loss: 0.0751 - val_loss: 0.0754\n","Epoch 20/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.0732 - val_loss: 0.0741\n","Epoch 21/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.0726 - val_loss: 0.0737\n","Epoch 22/100\n","34/34 [==============================] - 0s 7ms/step - loss: 0.0723 - val_loss: 0.0735\n","Epoch 23/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.0726 - val_loss: 0.0735\n","Epoch 24/100\n","34/34 [==============================] - 0s 7ms/step - loss: 0.0718 - val_loss: 0.0729\n","Epoch 25/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.0706 - val_loss: 0.0725\n","Epoch 26/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.0708 - val_loss: 0.0722\n","Epoch 27/100\n","34/34 [==============================] - 0s 6ms/step - loss: 0.0703 - val_loss: 0.0721\n","Epoch 28/100\n","34/34 [==============================] - 0s 5ms/step - loss: 0.0706 - val_loss: 0.0724\n","Epoch 29/100\n","34/34 [==============================] - 0s 7ms/step - loss: 0.0696 - val_loss: 0.0729\n","Epoch 30/100\n","34/34 [==============================] - 0s 8ms/step - loss: 0.0693 - val_loss: 0.0727\n","Epoch 31/100\n","34/34 [==============================] - 0s 9ms/step - loss: 0.0700 - val_loss: 0.0733\n","Epoch 32/100\n","32/34 [===========================>..] - ETA: 0s - loss: 0.0697Restoring model weights from the end of the best epoch: 27.\n","34/34 [==============================] - 0s 9ms/step - loss: 0.0699 - val_loss: 0.0737\n","Epoch 32: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0a0fd600a0>"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["reconstructions = autoencoder.predict(x_val)\n","train_loss = tf.keras.losses.mae(reconstructions, x_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bJNay0skXF4e","executionInfo":{"status":"ok","timestamp":1680855850996,"user_tz":-540,"elapsed":711,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"abd04e80-a7f5-4d4d-bcfc-56097e08eed9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["21/21 [==============================] - 0s 2ms/step\n"]}]},{"cell_type":"code","source":["threshold = np.mean(train_loss) + np.std(train_loss)\n","print(\"Threshold: \", threshold)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHwQTFkUwfne","executionInfo":{"status":"ok","timestamp":1680855852650,"user_tz":-540,"elapsed":5,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"a4724b4b-3557-4c27-be14-e35a250dbe00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Threshold:  0.3233443026341315\n"]}]},{"cell_type":"code","source":["plt.hist(train_loss[None, :], bins=50)\n","plt.xlabel(\"Test loss\")\n","plt.ylabel(\"No of examples\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"KNgwiOs9cRiP","executionInfo":{"status":"ok","timestamp":1680855855307,"user_tz":-540,"elapsed":400,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"1801b8d9-a6ea-4c6e-c435-882aaf824b0c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["def predict(model, data, threshold):\n","  reconstructions = model(data)\n","  loss = tf.keras.losses.mae(reconstructions, data)\n","  pred = tf.math.less(loss, threshold)\n","  pred = np.where(pred,0,1)\n","  return pred\n","\n","def print_stats(predictions, labels):\n","  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n","\n"],"metadata":{"id":"yxfX6lKlwjza"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = predict(autoencoder, x_val, threshold)\n","print_stats(preds, np.array([0]*x_val.shape[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ke8EDqnsxXC8","executionInfo":{"status":"ok","timestamp":1680855865984,"user_tz":-540,"elapsed":1261,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"89d9dfba-bad5-4b40-bf4e-54cd09147386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy = 0.810477657935285\n"]}]},{"cell_type":"code","source":["autoencoder.fit(train_df, train_df, epochs = 100, callbacks = [es], validation_split = 0.3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4nI1SgJGm5b","executionInfo":{"status":"ok","timestamp":1680855880082,"user_tz":-540,"elapsed":2602,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"41f83234-3e9b-4c0c-d5f6-69f84dd2bd04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","48/48 [==============================] - 0s 7ms/step - loss: 0.0729 - val_loss: 0.0634\n","Epoch 2/100\n","48/48 [==============================] - 0s 6ms/step - loss: 0.0722 - val_loss: 0.0645\n","Epoch 3/100\n","48/48 [==============================] - 0s 6ms/step - loss: 0.0724 - val_loss: 0.0652\n","Epoch 4/100\n","48/48 [==============================] - 0s 6ms/step - loss: 0.0721 - val_loss: 0.0663\n","Epoch 5/100\n","48/48 [==============================] - 0s 6ms/step - loss: 0.0718 - val_loss: 0.0651\n","Epoch 6/100\n","41/48 [========================>.....] - ETA: 0s - loss: 0.0724Restoring model weights from the end of the best epoch: 1.\n","48/48 [==============================] - 0s 6ms/step - loss: 0.0714 - val_loss: 0.0651\n","Epoch 6: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0a0e44f730>"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["autoencoder.save_weights('/content/drive/MyDrive/Colab Notebooks/AI_SPARK/AI_SPARK_Challenge_2023/권석원/autoencoder.h5')"],"metadata":{"id":"MIZQY2NFcpqi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 4개"],"metadata":{"id":"FasUNDNe1W4G"}},{"cell_type":"code","source":["type_list = []\n","type_tmp_2 = []\n","type_tmp_1 = []\n","type_tmp_5 = []\n","type_tmp_e = []\n","\n","\n","for i,row in df_data.iterrows():\n","  #print(row)\n","  \n","  if row['type'] == 20:\n","    type_tmp_2.append(row)\n","  elif row['type'] == 10:\n","    type_tmp_1.append(row)\n","  elif row['type'] == 50:\n","    type_tmp_5.append(row)\n","  else:\n","    type_tmp_e.append(row)\n","\n","type_list.append(type_tmp_2)\n","type_list.append(type_tmp_1)\n","type_list.append(type_tmp_5)\n","type_list.append(type_tmp_e)"],"metadata":{"id":"FBSRXWYJ1hrK","executionInfo":{"status":"ok","timestamp":1680882446820,"user_tz":-540,"elapsed":1,"user":{"displayName":"권석원","userId":"05764927584241177010"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["df_list = []\n","\n","for ls in type_list:\n","  df = pd.DataFrame(ls).drop(axis=1,columns=['type'])\n","  df_list.append(df)\n","  print(df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KpMkZqFv8jB_","executionInfo":{"status":"ok","timestamp":1680882449405,"user_tz":-540,"elapsed":519,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"9d18d5dc-6086-459a-bea6-1cc5f551a737"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["(328, 6)\n","(315, 6)\n","(96, 6)\n","(1422, 6)\n"]}]},{"cell_type":"code","source":["models = []\n","scalers = []\n","clear_session()\n","\n","for i in range(4):\n","  print('='*30)\n","  print(i)\n","\n","  df = df_list[i]\n","  model_tmp = DeepSVDD(preprocessing=False)\n","  #model_tmp = model(df.shape[1])\n","  #model_tmp.compile(optimizer='adam', loss='mse')\n","\n","  es = EarlyStopping(monitor = 'val_loss',patience=5,restore_best_weights=True, verbose=1)\n","\n","  scaler = MinMaxScaler()\n","  scarer_df = scaler.fit_transform(df)\n","  scalers.append(scaler)\n","\n","  model_tmp.fit(scarer_df)\n","  #model_tmp.fit(scarer_df, scarer_df, epochs = 100, callbacks = [es], validation_split = 0.3)\n","\n","  models.append(model_tmp)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOJ_qxPz9HIK","executionInfo":{"status":"ok","timestamp":1680883105932,"user_tz":-540,"elapsed":33632,"user":{"displayName":"권석원","userId":"05764927584241177010"}},"outputId":"e1ce7d75-0742-4d08-ce9d-b6c4ea33dcc7"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["==============================\n","0\n","11/11 [==============================] - 0s 1ms/step\n","Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 6)]               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                384       \n","                                                                 \n"," net_output (Dense)          (None, 32)                2048      \n","                                                                 \n"," tf.math.subtract_1 (TFOpLam  (None, 32)               0         \n"," bda)                                                            \n","                                                                 \n"," tf.math.pow_1 (TFOpLambda)  (None, 32)                0         \n","                                                                 \n"," tf.math.reduce_sum_1 (TFOpL  (None,)                  0         \n"," ambda)                                                          \n","                                                                 \n"," tf.math.reduce_mean_1 (TFOp  ()                       0         \n"," Lambda)                                                         \n","                                                                 \n"," tf.__operators__.add_1 (TFO  ()                       0         \n"," pLambda)                                                        \n","                                                                 \n"," add_loss_1 (AddLoss)        ()                        0         \n","                                                                 \n","=================================================================\n","Total params: 2,432\n","Trainable params: 2,432\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/100\n","10/10 [==============================] - 1s 19ms/step - loss: 1.2207 - val_loss: 0.9952\n","Epoch 2/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.9489 - val_loss: 0.8765\n","Epoch 3/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.8126 - val_loss: 0.8235\n","Epoch 4/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7617 - val_loss: 0.8061\n","Epoch 5/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7377 - val_loss: 0.7951\n","Epoch 6/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.7229 - val_loss: 0.7866\n","Epoch 7/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.7075 - val_loss: 0.7762\n","Epoch 8/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6956 - val_loss: 0.7600\n","Epoch 9/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6682 - val_loss: 0.7395\n","Epoch 10/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6433 - val_loss: 0.7338\n","Epoch 11/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6383 - val_loss: 0.7315\n","Epoch 12/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6308 - val_loss: 0.7271\n","Epoch 13/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6271 - val_loss: 0.7240\n","Epoch 14/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6284 - val_loss: 0.7238\n","Epoch 15/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.6199 - val_loss: 0.7185\n","Epoch 16/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6172 - val_loss: 0.7136\n","Epoch 17/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6142 - val_loss: 0.7094\n","Epoch 18/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6101 - val_loss: 0.7013\n","Epoch 19/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.6045 - val_loss: 0.7010\n","Epoch 20/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.5979 - val_loss: 0.6966\n","Epoch 21/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5998 - val_loss: 0.6954\n","Epoch 22/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5980 - val_loss: 0.6907\n","Epoch 23/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5852 - val_loss: 0.6906\n","Epoch 24/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5874 - val_loss: 0.6809\n","Epoch 25/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5898 - val_loss: 0.6797\n","Epoch 26/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5866 - val_loss: 0.6764\n","Epoch 27/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.5753 - val_loss: 0.6737\n","Epoch 28/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5746 - val_loss: 0.6691\n","Epoch 29/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5681 - val_loss: 0.6656\n","Epoch 30/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.5734 - val_loss: 0.6631\n","Epoch 31/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5732 - val_loss: 0.6627\n","Epoch 32/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5662 - val_loss: 0.6561\n","Epoch 33/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.5738 - val_loss: 0.6542\n","Epoch 34/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5644 - val_loss: 0.6565\n","Epoch 35/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5689 - val_loss: 0.6523\n","Epoch 36/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5600 - val_loss: 0.6498\n","Epoch 37/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5554 - val_loss: 0.6471\n","Epoch 38/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5499 - val_loss: 0.6416\n","Epoch 39/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.5428 - val_loss: 0.6229\n","Epoch 40/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5221 - val_loss: 0.6252\n","Epoch 41/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5245 - val_loss: 0.6137\n","Epoch 42/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5303 - val_loss: 0.6117\n","Epoch 43/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5191 - val_loss: 0.6134\n","Epoch 44/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5274 - val_loss: 0.6130\n","Epoch 45/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5206 - val_loss: 0.6053\n","Epoch 46/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5188 - val_loss: 0.6090\n","Epoch 47/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5146 - val_loss: 0.6046\n","Epoch 48/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5128 - val_loss: 0.6036\n","Epoch 49/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5103 - val_loss: 0.5997\n","Epoch 50/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5179 - val_loss: 0.6002\n","Epoch 51/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5124 - val_loss: 0.5947\n","Epoch 52/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5032 - val_loss: 0.5922\n","Epoch 53/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5039 - val_loss: 0.5934\n","Epoch 54/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.5076 - val_loss: 0.5896\n","Epoch 55/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.5059 - val_loss: 0.5857\n","Epoch 56/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.5068 - val_loss: 0.5902\n","Epoch 57/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.5019 - val_loss: 0.5882\n","Epoch 58/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.4999 - val_loss: 0.5801\n","Epoch 59/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.5006 - val_loss: 0.5837\n","Epoch 60/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.5021 - val_loss: 0.5787\n","Epoch 61/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4992 - val_loss: 0.5778\n","Epoch 62/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4977 - val_loss: 0.5761\n","Epoch 63/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4988 - val_loss: 0.5771\n","Epoch 64/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.5028 - val_loss: 0.5732\n","Epoch 65/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.5016 - val_loss: 0.5670\n","Epoch 66/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.4933 - val_loss: 0.5733\n","Epoch 67/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4912 - val_loss: 0.5653\n","Epoch 68/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.4895 - val_loss: 0.5648\n","Epoch 69/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.4933 - val_loss: 0.5602\n","Epoch 70/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4865 - val_loss: 0.5652\n","Epoch 71/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4880 - val_loss: 0.5593\n","Epoch 72/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4876 - val_loss: 0.5570\n","Epoch 73/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4848 - val_loss: 0.5527\n","Epoch 74/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4891 - val_loss: 0.5559\n","Epoch 75/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4868 - val_loss: 0.5499\n","Epoch 76/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4840 - val_loss: 0.5505\n","Epoch 77/100\n","10/10 [==============================] - 0s 8ms/step - loss: 0.4797 - val_loss: 0.5447\n","Epoch 78/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4846 - val_loss: 0.5420\n","Epoch 79/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4800 - val_loss: 0.5466\n","Epoch 80/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4785 - val_loss: 0.5433\n","Epoch 81/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4769 - val_loss: 0.5358\n","Epoch 82/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4743 - val_loss: 0.5342\n","Epoch 83/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4748 - val_loss: 0.5346\n","Epoch 84/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4742 - val_loss: 0.5305\n","Epoch 85/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4750 - val_loss: 0.5282\n","Epoch 86/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.4727 - val_loss: 0.5268\n","Epoch 87/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4680 - val_loss: 0.5279\n","Epoch 88/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4676 - val_loss: 0.5256\n","Epoch 89/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4654 - val_loss: 0.5266\n","Epoch 90/100\n","10/10 [==============================] - 0s 6ms/step - loss: 0.4673 - val_loss: 0.5250\n","Epoch 91/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4726 - val_loss: 0.5178\n","Epoch 92/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4697 - val_loss: 0.5155\n","Epoch 93/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4625 - val_loss: 0.5167\n","Epoch 94/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4650 - val_loss: 0.5129\n","Epoch 95/100\n","10/10 [==============================] - 0s 4ms/step - loss: 0.4627 - val_loss: 0.5127\n","Epoch 96/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4605 - val_loss: 0.5093\n","Epoch 97/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4593 - val_loss: 0.5089\n","Epoch 98/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4631 - val_loss: 0.5107\n","Epoch 99/100\n","10/10 [==============================] - 0s 5ms/step - loss: 0.4624 - val_loss: 0.5062\n","Epoch 100/100\n","10/10 [==============================] - 0s 7ms/step - loss: 0.4620 - val_loss: 0.5038\n","11/11 [==============================] - 0s 1ms/step\n","==============================\n","1\n","10/10 [==============================] - 0s 1ms/step\n","Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 6)]               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 64)                384       \n","                                                                 \n"," net_output (Dense)          (None, 32)                2048      \n","                                                                 \n"," tf.math.subtract_3 (TFOpLam  (None, 32)               0         \n"," bda)                                                            \n","                                                                 \n"," tf.math.pow_3 (TFOpLambda)  (None, 32)                0         \n","                                                                 \n"," tf.math.reduce_sum_3 (TFOpL  (None,)                  0         \n"," ambda)                                                          \n","                                                                 \n"," tf.math.reduce_mean_3 (TFOp  ()                       0         \n"," Lambda)                                                         \n","                                                                 \n"," tf.__operators__.add_3 (TFO  ()                       0         \n"," pLambda)                                                        \n","                                                                 \n"," add_loss_3 (AddLoss)        ()                        0         \n","                                                                 \n","=================================================================\n","Total params: 2,432\n","Trainable params: 2,432\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/100\n","9/9 [==============================] - 0s 16ms/step - loss: 0.5804 - val_loss: 0.4394\n","Epoch 2/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.3975 - val_loss: 0.3380\n","Epoch 3/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.3261 - val_loss: 0.3043\n","Epoch 4/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2997 - val_loss: 0.2844\n","Epoch 5/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2800 - val_loss: 0.2679\n","Epoch 6/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.2677 - val_loss: 0.2582\n","Epoch 7/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2589 - val_loss: 0.2511\n","Epoch 8/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2521 - val_loss: 0.2455\n","Epoch 9/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2465 - val_loss: 0.2406\n","Epoch 10/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2422 - val_loss: 0.2368\n","Epoch 11/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2379 - val_loss: 0.2332\n","Epoch 12/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2353 - val_loss: 0.2301\n","Epoch 13/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2317 - val_loss: 0.2273\n","Epoch 14/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2296 - val_loss: 0.2249\n","Epoch 15/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2258 - val_loss: 0.2170\n","Epoch 16/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2152 - val_loss: 0.2080\n","Epoch 17/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2099 - val_loss: 0.2051\n","Epoch 18/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.2042 - val_loss: 0.1978\n","Epoch 19/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1998 - val_loss: 0.1968\n","Epoch 20/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1983 - val_loss: 0.1951\n","Epoch 21/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1955 - val_loss: 0.1886\n","Epoch 22/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1898 - val_loss: 0.1865\n","Epoch 23/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1891 - val_loss: 0.1855\n","Epoch 24/100\n","9/9 [==============================] - 0s 6ms/step - loss: 0.1879 - val_loss: 0.1852\n","Epoch 25/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1870 - val_loss: 0.1837\n","Epoch 26/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1861 - val_loss: 0.1832\n","Epoch 27/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1854 - val_loss: 0.1825\n","Epoch 28/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1852 - val_loss: 0.1822\n","Epoch 29/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1846 - val_loss: 0.1817\n","Epoch 30/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1838 - val_loss: 0.1810\n","Epoch 31/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1830 - val_loss: 0.1787\n","Epoch 32/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1792 - val_loss: 0.1739\n","Epoch 33/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1765 - val_loss: 0.1739\n","Epoch 34/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1761 - val_loss: 0.1728\n","Epoch 35/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1751 - val_loss: 0.1726\n","Epoch 36/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1749 - val_loss: 0.1728\n","Epoch 37/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1745 - val_loss: 0.1720\n","Epoch 38/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1743 - val_loss: 0.1718\n","Epoch 39/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1741 - val_loss: 0.1715\n","Epoch 40/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1742 - val_loss: 0.1711\n","Epoch 41/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1740 - val_loss: 0.1709\n","Epoch 42/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1747 - val_loss: 0.1712\n","Epoch 43/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1735 - val_loss: 0.1706\n","Epoch 44/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1728 - val_loss: 0.1713\n","Epoch 45/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1734 - val_loss: 0.1702\n","Epoch 46/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1726 - val_loss: 0.1702\n","Epoch 47/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1727 - val_loss: 0.1700\n","Epoch 48/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1722 - val_loss: 0.1706\n","Epoch 49/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1726 - val_loss: 0.1697\n","Epoch 50/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1723 - val_loss: 0.1700\n","Epoch 51/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1724 - val_loss: 0.1695\n","Epoch 52/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1737 - val_loss: 0.1698\n","Epoch 53/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1729 - val_loss: 0.1699\n","Epoch 54/100\n","9/9 [==============================] - 0s 7ms/step - loss: 0.1721 - val_loss: 0.1693\n","Epoch 55/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1728 - val_loss: 0.1695\n","Epoch 56/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1728 - val_loss: 0.1690\n","Epoch 57/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1706 - val_loss: 0.1654\n","Epoch 58/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1669 - val_loss: 0.1611\n","Epoch 59/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1650 - val_loss: 0.1614\n","Epoch 60/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1638 - val_loss: 0.1605\n","Epoch 61/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1640 - val_loss: 0.1622\n","Epoch 62/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1656 - val_loss: 0.1603\n","Epoch 63/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1647 - val_loss: 0.1605\n","Epoch 64/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1634 - val_loss: 0.1613\n","Epoch 65/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1639 - val_loss: 0.1602\n","Epoch 66/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1631 - val_loss: 0.1612\n","Epoch 67/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1629 - val_loss: 0.1601\n","Epoch 68/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1624 - val_loss: 0.1605\n","Epoch 69/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1623 - val_loss: 0.1600\n","Epoch 70/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1625 - val_loss: 0.1598\n","Epoch 71/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1628 - val_loss: 0.1606\n","Epoch 72/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1632 - val_loss: 0.1597\n","Epoch 73/100\n","9/9 [==============================] - 0s 7ms/step - loss: 0.1629 - val_loss: 0.1609\n","Epoch 74/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1626 - val_loss: 0.1596\n","Epoch 75/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1628 - val_loss: 0.1601\n","Epoch 76/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1620 - val_loss: 0.1595\n","Epoch 77/100\n","9/9 [==============================] - 0s 6ms/step - loss: 0.1613 - val_loss: 0.1598\n","Epoch 78/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1623 - val_loss: 0.1595\n","Epoch 79/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1626 - val_loss: 0.1601\n","Epoch 80/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1627 - val_loss: 0.1594\n","Epoch 81/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1628 - val_loss: 0.1595\n","Epoch 82/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1637 - val_loss: 0.1594\n","Epoch 83/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1638 - val_loss: 0.1596\n","Epoch 84/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1629 - val_loss: 0.1595\n","Epoch 85/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1617 - val_loss: 0.1592\n","Epoch 86/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1633 - val_loss: 0.1597\n","Epoch 87/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1618 - val_loss: 0.1592\n","Epoch 88/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1598\n","Epoch 89/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1620 - val_loss: 0.1591\n","Epoch 90/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1621 - val_loss: 0.1591\n","Epoch 91/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1622 - val_loss: 0.1599\n","Epoch 92/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1609 - val_loss: 0.1590\n","Epoch 93/100\n","9/9 [==============================] - 0s 7ms/step - loss: 0.1619 - val_loss: 0.1591\n","Epoch 94/100\n","9/9 [==============================] - 0s 7ms/step - loss: 0.1612 - val_loss: 0.1592\n","Epoch 95/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1593\n","Epoch 96/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.1589\n","Epoch 97/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1592\n","Epoch 98/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1591\n","Epoch 99/100\n","9/9 [==============================] - 0s 5ms/step - loss: 0.1618 - val_loss: 0.1594\n","Epoch 100/100\n","9/9 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1594\n","10/10 [==============================] - 0s 2ms/step\n","==============================\n","2\n","3/3 [==============================] - 0s 6ms/step\n","Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 6)]               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 64)                384       \n","                                                                 \n"," net_output (Dense)          (None, 32)                2048      \n","                                                                 \n"," tf.math.subtract_5 (TFOpLam  (None, 32)               0         \n"," bda)                                                            \n","                                                                 \n"," tf.math.pow_5 (TFOpLambda)  (None, 32)                0         \n","                                                                 \n"," tf.math.reduce_sum_5 (TFOpL  (None,)                  0         \n"," ambda)                                                          \n","                                                                 \n"," tf.math.reduce_mean_5 (TFOp  ()                       0         \n"," Lambda)                                                         \n","                                                                 \n"," tf.__operators__.add_5 (TFO  ()                       0         \n"," pLambda)                                                        \n","                                                                 \n"," add_loss_5 (AddLoss)        ()                        0         \n","                                                                 \n","=================================================================\n","Total params: 2,432\n","Trainable params: 2,432\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/100\n","3/3 [==============================] - 1s 89ms/step - loss: 1.1922 - val_loss: 1.1064\n","Epoch 2/100\n","3/3 [==============================] - 0s 17ms/step - loss: 1.0046 - val_loss: 0.9481\n","Epoch 3/100\n","3/3 [==============================] - 0s 31ms/step - loss: 0.8656 - val_loss: 0.8271\n","Epoch 4/100\n","3/3 [==============================] - 0s 35ms/step - loss: 0.7763 - val_loss: 0.7376\n","Epoch 5/100\n","3/3 [==============================] - 0s 33ms/step - loss: 0.6861 - val_loss: 0.6673\n","Epoch 6/100\n","3/3 [==============================] - 0s 30ms/step - loss: 0.6251 - val_loss: 0.6148\n","Epoch 7/100\n","3/3 [==============================] - 0s 22ms/step - loss: 0.5812 - val_loss: 0.5761\n","Epoch 8/100\n","3/3 [==============================] - 0s 29ms/step - loss: 0.5456 - val_loss: 0.5471\n","Epoch 9/100\n","3/3 [==============================] - 0s 24ms/step - loss: 0.5221 - val_loss: 0.5250\n","Epoch 10/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.5011 - val_loss: 0.5069\n","Epoch 11/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.4840 - val_loss: 0.4910\n","Epoch 12/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.4694 - val_loss: 0.4782\n","Epoch 13/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.4601 - val_loss: 0.4684\n","Epoch 14/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.4476 - val_loss: 0.4608\n","Epoch 15/100\n","3/3 [==============================] - 0s 20ms/step - loss: 0.4410 - val_loss: 0.4549\n","Epoch 16/100\n","3/3 [==============================] - 0s 18ms/step - loss: 0.4343 - val_loss: 0.4497\n","Epoch 17/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.4310 - val_loss: 0.4448\n","Epoch 18/100\n","3/3 [==============================] - 0s 19ms/step - loss: 0.4255 - val_loss: 0.4401\n","Epoch 19/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.4211 - val_loss: 0.4358\n","Epoch 20/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.4169 - val_loss: 0.4318\n","Epoch 21/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.4127 - val_loss: 0.4281\n","Epoch 22/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.4112 - val_loss: 0.4245\n","Epoch 23/100\n","3/3 [==============================] - 0s 19ms/step - loss: 0.4073 - val_loss: 0.4206\n","Epoch 24/100\n","3/3 [==============================] - 0s 26ms/step - loss: 0.4012 - val_loss: 0.4170\n","Epoch 25/100\n","3/3 [==============================] - 0s 26ms/step - loss: 0.4017 - val_loss: 0.4137\n","Epoch 26/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.3946 - val_loss: 0.4109\n","Epoch 27/100\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3926 - val_loss: 0.4077\n","Epoch 28/100\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3875 - val_loss: 0.4042\n","Epoch 29/100\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3858 - val_loss: 0.4010\n","Epoch 30/100\n","3/3 [==============================] - 0s 22ms/step - loss: 0.3838 - val_loss: 0.3977\n","Epoch 31/100\n","3/3 [==============================] - 0s 25ms/step - loss: 0.3813 - val_loss: 0.3951\n","Epoch 32/100\n","3/3 [==============================] - 0s 24ms/step - loss: 0.3772 - val_loss: 0.3930\n","Epoch 33/100\n","3/3 [==============================] - 0s 26ms/step - loss: 0.3742 - val_loss: 0.3901\n","Epoch 34/100\n","3/3 [==============================] - 0s 19ms/step - loss: 0.3713 - val_loss: 0.3875\n","Epoch 35/100\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3664 - val_loss: 0.3849\n","Epoch 36/100\n","3/3 [==============================] - 0s 18ms/step - loss: 0.3700 - val_loss: 0.3827\n","Epoch 37/100\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3664 - val_loss: 0.3807\n","Epoch 38/100\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3626 - val_loss: 0.3791\n","Epoch 39/100\n","3/3 [==============================] - 0s 20ms/step - loss: 0.3645 - val_loss: 0.3776\n","Epoch 40/100\n","3/3 [==============================] - 0s 28ms/step - loss: 0.3597 - val_loss: 0.3755\n","Epoch 41/100\n","3/3 [==============================] - 0s 28ms/step - loss: 0.3571 - val_loss: 0.3733\n","Epoch 42/100\n","3/3 [==============================] - 0s 25ms/step - loss: 0.3560 - val_loss: 0.3715\n","Epoch 43/100\n","3/3 [==============================] - 0s 28ms/step - loss: 0.3562 - val_loss: 0.3698\n","Epoch 44/100\n","3/3 [==============================] - 0s 18ms/step - loss: 0.3559 - val_loss: 0.3681\n","Epoch 45/100\n","3/3 [==============================] - 0s 18ms/step - loss: 0.3537 - val_loss: 0.3668\n","Epoch 46/100\n","3/3 [==============================] - 0s 21ms/step - loss: 0.3512 - val_loss: 0.3656\n","Epoch 47/100\n","3/3 [==============================] - 0s 22ms/step - loss: 0.3479 - val_loss: 0.3646\n","Epoch 48/100\n","3/3 [==============================] - 0s 21ms/step - loss: 0.3449 - val_loss: 0.3636\n","Epoch 49/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.3454 - val_loss: 0.3621\n","Epoch 50/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3440 - val_loss: 0.3605\n","Epoch 51/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.3442 - val_loss: 0.3592\n","Epoch 52/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3445 - val_loss: 0.3580\n","Epoch 53/100\n","3/3 [==============================] - 0s 18ms/step - loss: 0.3436 - val_loss: 0.3574\n","Epoch 54/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3431 - val_loss: 0.3564\n","Epoch 55/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3439 - val_loss: 0.3555\n","Epoch 56/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3422 - val_loss: 0.3550\n","Epoch 57/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3384 - val_loss: 0.3540\n","Epoch 58/100\n","3/3 [==============================] - 0s 19ms/step - loss: 0.3360 - val_loss: 0.3526\n","Epoch 59/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3375 - val_loss: 0.3515\n","Epoch 60/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3359 - val_loss: 0.3509\n","Epoch 61/100\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3363 - val_loss: 0.3507\n","Epoch 62/100\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3336 - val_loss: 0.3500\n","Epoch 63/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3370 - val_loss: 0.3491\n","Epoch 64/100\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3374 - val_loss: 0.3484\n","Epoch 65/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.3374 - val_loss: 0.3482\n","Epoch 66/100\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3331 - val_loss: 0.3478\n","Epoch 67/100\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3340 - val_loss: 0.3471\n","Epoch 68/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3290 - val_loss: 0.3463\n","Epoch 69/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.3334 - val_loss: 0.3456\n","Epoch 70/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3320 - val_loss: 0.3450\n","Epoch 71/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3279 - val_loss: 0.3448\n","Epoch 72/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3321 - val_loss: 0.3443\n","Epoch 73/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3281 - val_loss: 0.3442\n","Epoch 74/100\n","3/3 [==============================] - 0s 13ms/step - loss: 0.3258 - val_loss: 0.3435\n","Epoch 75/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3249 - val_loss: 0.3430\n","Epoch 76/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.3286 - val_loss: 0.3421\n","Epoch 77/100\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3291 - val_loss: 0.3416\n","Epoch 78/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.3259 - val_loss: 0.3414\n","Epoch 79/100\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3243 - val_loss: 0.3413\n","Epoch 80/100\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3276 - val_loss: 0.3406\n","Epoch 81/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3283 - val_loss: 0.3405\n","Epoch 82/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.3264 - val_loss: 0.3401\n","Epoch 83/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3235 - val_loss: 0.3395\n","Epoch 84/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3237 - val_loss: 0.3390\n","Epoch 85/100\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3251 - val_loss: 0.3387\n","Epoch 86/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3248 - val_loss: 0.3386\n","Epoch 87/100\n","3/3 [==============================] - 0s 13ms/step - loss: 0.3240 - val_loss: 0.3383\n","Epoch 88/100\n","3/3 [==============================] - 0s 13ms/step - loss: 0.3210 - val_loss: 0.3380\n","Epoch 89/100\n","3/3 [==============================] - 0s 16ms/step - loss: 0.3212 - val_loss: 0.3376\n","Epoch 90/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3239 - val_loss: 0.3371\n","Epoch 91/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3213 - val_loss: 0.3371\n","Epoch 92/100\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3212 - val_loss: 0.3364\n","Epoch 93/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3208 - val_loss: 0.3364\n","Epoch 94/100\n","3/3 [==============================] - 0s 14ms/step - loss: 0.3200 - val_loss: 0.3357\n","Epoch 95/100\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3232 - val_loss: 0.3357\n","Epoch 96/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3208 - val_loss: 0.3359\n","Epoch 97/100\n","3/3 [==============================] - 0s 13ms/step - loss: 0.3171 - val_loss: 0.3357\n","Epoch 98/100\n","3/3 [==============================] - 0s 15ms/step - loss: 0.3214 - val_loss: 0.3348\n","Epoch 99/100\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3182 - val_loss: 0.3345\n","Epoch 100/100\n","3/3 [==============================] - 0s 17ms/step - loss: 0.3235 - val_loss: 0.3344\n","3/3 [==============================] - 0s 3ms/step\n","==============================\n","3\n","45/45 [==============================] - 0s 1ms/step\n","Model: \"model_11\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 6)]               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 64)                384       \n","                                                                 \n"," net_output (Dense)          (None, 32)                2048      \n","                                                                 \n"," tf.math.subtract_7 (TFOpLam  (None, 32)               0         \n"," bda)                                                            \n","                                                                 \n"," tf.math.pow_7 (TFOpLambda)  (None, 32)                0         \n","                                                                 \n"," tf.math.reduce_sum_7 (TFOpL  (None,)                  0         \n"," ambda)                                                          \n","                                                                 \n"," tf.math.reduce_mean_7 (TFOp  ()                       0         \n"," Lambda)                                                         \n","                                                                 \n"," tf.__operators__.add_7 (TFO  ()                       0         \n"," pLambda)                                                        \n","                                                                 \n"," add_loss_7 (AddLoss)        ()                        0         \n","                                                                 \n","=================================================================\n","Total params: 2,432\n","Trainable params: 2,432\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/100\n","40/40 [==============================] - 0s 4ms/step - loss: 0.6849 - val_loss: 0.5921\n","Epoch 2/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.5692 - val_loss: 0.5422\n","Epoch 3/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.4108\n","Epoch 4/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3957 - val_loss: 0.3877\n","Epoch 5/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.3789\n","Epoch 6/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.3684\n","Epoch 7/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.3658\n","Epoch 8/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.3625\n","Epoch 9/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3513 - val_loss: 0.3442\n","Epoch 10/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3464 - val_loss: 0.3445\n","Epoch 11/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3451 - val_loss: 0.3413\n","Epoch 12/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3436 - val_loss: 0.3350\n","Epoch 13/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3372 - val_loss: 0.3347\n","Epoch 14/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3359 - val_loss: 0.3342\n","Epoch 15/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3360 - val_loss: 0.3340\n","Epoch 16/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3360 - val_loss: 0.3329\n","Epoch 17/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.3323\n","Epoch 18/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3367 - val_loss: 0.3315\n","Epoch 19/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3348 - val_loss: 0.3314\n","Epoch 20/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3341 - val_loss: 0.3316\n","Epoch 21/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3346 - val_loss: 0.3312\n","Epoch 22/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.3314\n","Epoch 23/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3335 - val_loss: 0.3304\n","Epoch 24/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.3313\n","Epoch 25/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3334 - val_loss: 0.3316\n","Epoch 26/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3331 - val_loss: 0.3299\n","Epoch 27/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3328 - val_loss: 0.3300\n","Epoch 28/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3325 - val_loss: 0.3298\n","Epoch 29/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3335 - val_loss: 0.3297\n","Epoch 30/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.3296\n","Epoch 31/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3322 - val_loss: 0.3292\n","Epoch 32/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3327 - val_loss: 0.3294\n","Epoch 33/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3326 - val_loss: 0.3298\n","Epoch 34/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3322 - val_loss: 0.3294\n","Epoch 35/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.3289\n","Epoch 36/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3322 - val_loss: 0.3286\n","Epoch 37/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3324 - val_loss: 0.3285\n","Epoch 38/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3316 - val_loss: 0.3289\n","Epoch 39/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3325 - val_loss: 0.3283\n","Epoch 40/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.3286\n","Epoch 41/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3319 - val_loss: 0.3290\n","Epoch 42/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3323 - val_loss: 0.3279\n","Epoch 43/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.3280\n","Epoch 44/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3313 - val_loss: 0.3296\n","Epoch 45/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3315 - val_loss: 0.3278\n","Epoch 46/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3316 - val_loss: 0.3278\n","Epoch 47/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3322 - val_loss: 0.3300\n","Epoch 48/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3309 - val_loss: 0.3277\n","Epoch 49/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3309 - val_loss: 0.3284\n","Epoch 50/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3315 - val_loss: 0.3278\n","Epoch 51/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3306 - val_loss: 0.3276\n","Epoch 52/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.3271\n","Epoch 53/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.3272\n","Epoch 54/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3301 - val_loss: 0.3280\n","Epoch 55/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.3277\n","Epoch 56/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3302 - val_loss: 0.3279\n","Epoch 57/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.3275\n","Epoch 58/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3276\n","Epoch 59/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3292 - val_loss: 0.3269\n","Epoch 60/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.3284\n","Epoch 61/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3276\n","Epoch 62/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3301 - val_loss: 0.3264\n","Epoch 63/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3316 - val_loss: 0.3272\n","Epoch 64/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.3268\n","Epoch 65/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3308 - val_loss: 0.3261\n","Epoch 66/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.3261\n","Epoch 67/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3271\n","Epoch 68/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3291 - val_loss: 0.3268\n","Epoch 69/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.3259\n","Epoch 70/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.3258\n","Epoch 71/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3289 - val_loss: 0.3264\n","Epoch 72/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3294 - val_loss: 0.3346\n","Epoch 73/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3293 - val_loss: 0.3283\n","Epoch 74/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3302 - val_loss: 0.3257\n","Epoch 75/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3289 - val_loss: 0.3323\n","Epoch 76/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3293 - val_loss: 0.3262\n","Epoch 77/100\n","40/40 [==============================] - 0s 4ms/step - loss: 0.3283 - val_loss: 0.3277\n","Epoch 78/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.3290\n","Epoch 79/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.3260\n","Epoch 80/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3293 - val_loss: 0.3264\n","Epoch 81/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.3286\n","Epoch 82/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.3256\n","Epoch 83/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.3251\n","Epoch 84/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.3259\n","Epoch 85/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.3248\n","Epoch 86/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3277 - val_loss: 0.3251\n","Epoch 87/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.3261\n","Epoch 88/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3273 - val_loss: 0.3255\n","Epoch 89/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3272 - val_loss: 0.3246\n","Epoch 90/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3272 - val_loss: 0.3245\n","Epoch 91/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3276 - val_loss: 0.3260\n","Epoch 92/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3277 - val_loss: 0.3251\n","Epoch 93/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3272 - val_loss: 0.3261\n","Epoch 94/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3278 - val_loss: 0.3244\n","Epoch 95/100\n","40/40 [==============================] - 0s 2ms/step - loss: 0.3273 - val_loss: 0.3281\n","Epoch 96/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.3248\n","Epoch 97/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.3290\n","Epoch 98/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3280 - val_loss: 0.3241\n","Epoch 99/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3270 - val_loss: 0.3240\n","Epoch 100/100\n","40/40 [==============================] - 0s 3ms/step - loss: 0.3277 - val_loss: 0.3268\n","45/45 [==============================] - 0s 1ms/step\n"]}]},{"cell_type":"code","source":["string_list = ['2','1','5','e']\n","\n","for i,m in enumerate(models): \n","  #m.save_weights('/content/drive/MyDrive/Colab Notebooks/AI_SPARK/AI_SPARK_Challenge_2023/권석원/m_' + string_list[i] + '.h5')\n","  with open('/content/drive/MyDrive/Colab Notebooks/AI_SPARK/AI_SPARK_Challenge_2023/권석원/m_' + string_list[i] + '.pickle', 'wb') as f:\n","    pickle.dump(m, f)\n","  #m.save_weights('/content/drive/MyDrive/Colab Notebooks/AI_SPARK/AI_SPARK_Challenge_2023/권석원/m_' + string_list[i] + '.h5')\n","  \n","  with open('/content/drive/MyDrive/Colab Notebooks/AI_SPARK/AI_SPARK_Challenge_2023/권석원/s_' + string_list[i] + '.pickle', 'wb') as f:\n","    pickle.dump(scalers[i], f)\n"],"metadata":{"id":"oi2QAkOHBrf_","executionInfo":{"status":"ok","timestamp":1680883309613,"user_tz":-540,"elapsed":2079,"user":{"displayName":"권석원","userId":"05764927584241177010"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## KFold"],"metadata":{"id":"xDKA785_iiGO"}},{"cell_type":"code","source":["kf = KFold(random_state=2023,shuffle=True)"],"metadata":{"id":"YYD_HDoeilzA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, (train_index, test_index) in enumerate(kf.split(df_data)):\n","  print('='*10)\n","  print(i)\n","  print('='*10)\n","  x_train = df_data.loc[train_index]\n","  x_test = df_data.loc[test_index]\n","\n","  scaler = MinMaxScaler()\n","  x_train = scaler.fit_transform(x_train)\n","  x_test = scaler.transform(x_test)\n","\n","  "],"metadata":{"id":"45WbjihLjx6M"},"execution_count":null,"outputs":[]}]}